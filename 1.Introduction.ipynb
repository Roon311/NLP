{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![logo](https://drive.google.com/uc?export=view&id=1QJ9PAT9q-Ksv_Vs_pLXtLHxjjV-9FMTz)\n",
        "\n",
        "Created by: [Noureldin Mohamed](mailto:s-noureldin.hamedo@zewailcity.edu.eg)\n"
      ],
      "metadata": {
        "id": "gbFTmoCXy-7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table of Contents\n",
        "\n",
        "- [Introduction](#scrollTo=qWnhhhtY0psV)\n",
        "- [Building Blocks](#scrollTo=rufmCSTm0-Tb)\n"
      ],
      "metadata": {
        "id": "bDQS3PVPzOAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "\n",
        "<p>\n",
        "<b>NLP</b>, <b><font color='gren'> Natural Language Processing</font></b>\n",
        ", refers to the field of artificial intelligence focused on enabling machines to understand, interpret, and generate human language. It involves developing algorithms and models to analyze and process textual and spoken data. NLP plays a crucial role in applications like:\n",
        "\n",
        "<ul>\n",
        "<li> Text Understanding and Extraction\n",
        "<li> Chatbots and Virtual Assistants\n",
        "<li> Sentiment Analysis\n",
        "<li> Named Entity Recognition\n",
        "<li> Text Generation\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<h2><b>How does NLP Work?</b></h2>\n",
        "\n",
        "<img src=\"https://www.shaip.com/wp-content/uploads/2022/10/How-NLP-Works-760px.jpg\" width=\"600\">\n",
        "\n"
      ],
      "metadata": {
        "id": "qWnhhhtY0psV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Blocks**\n",
        "\n",
        "Before diving deeper into the vast realm of NLP models, we need to understand the essential steps required to get things working correctly.\n",
        "<br><br>\n",
        "<h3><b>Step 1: Preprocessing</b></h3>\n",
        "Text preprocessing serves as a crucial step in preparing text data for model input by eliminating noise, such as emotions, punctuation, and variations in case. In the realm of Human Language, expressing the same idea in diverse ways poses a significant challenge. This challenge stems from the fact that machines, unlike humans, require numerical input, compelling us to adeptly convert text into meaningful numerical representations.\n",
        "\n",
        "We will look into some common essential ways to preprocess your text.\n",
        "<h4><font color='gold'><b>Normalization</b></font></h4>\n",
        "\n",
        "<b>What is it?</b>\n",
        "\n",
        "Normalization is like tidying up your text. It involves making all text uniform, such as converting everything to lowercase. This helps the model treat words like <font color='gren'><b>\"apple\"</b></font> and <font color='gren'><b>\"Apple\"</b></font> the same way.\n",
        "\n",
        "\n",
        "```\n",
        "text=text.lower() # Convert to lower case\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "<b>Why do it?</b>\n",
        "\n",
        "It ensures consistency in your text data, so the model doesn't get confused by variations in capitalization.\n",
        "\n",
        "<h4><font color='gold'><b>Tokenization</b></font></h4>\n",
        "<b>What is it?</b>\n",
        "\n",
        "Tokenization is like breaking down a sentence into individual words. It helps the model understand and process each word separately.\n",
        "\n",
        "\n",
        "```\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
        "\n",
        "# Tokenize into words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Tokenize into sentences\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "<b>Why do it?</b>\n",
        "\n",
        "It's like giving the model a set of building blocks <font color='gren'><b>(words)</b></font> to work with, making it easier to analyze and understand the text.\n",
        "\n",
        "\n",
        "<h4><font color='gold'><b>Lemmatization</b></font></h4>\n",
        "\n",
        "<b>What is it?</b>\n",
        "\n",
        "Lemmatization is finding the base or root form of a word. For example, <font color='gren'><b>\"running\"</b></font> becomes <font color='gren'><b>\"run.\"</b></font> It helps the model focus on the core meaning.\n",
        "\n",
        "\n",
        "```\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
        "nltk.download('wordnet')  # Download the WordNet lemmatizer data\n",
        "\n",
        "# Tokenize into words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize each word\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "<b>Why do it?</b>\n",
        "\n",
        "It reduces words to their essential forms, preventing the model from treating similar words like <font color='gren'><b>(running, run, runs)</b></font> differently.\n",
        "\n",
        "\n",
        "<h4><font color='gold'><b>Stop Words Removal</b></font></h4>\n",
        "\n",
        "<b>What is it?</b>\n",
        "\n",
        "Stop words are common words like <font color='gren'><b>\"the\"\"</b></font> and <font color='gren'><b>\"and\"</b></font> that don't carry much meaning. Removing them helps the model focus on the important words.\n",
        "\n",
        "\n",
        "```\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
        "nltk.download('stopwords')  # Download the stopwords data\n",
        "\n",
        "# Tokenize into words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Get English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "```\n",
        "\n",
        "\n",
        "<b>Why do it?</b>\n",
        "\n",
        "It cleans up the text, leaving only the meaningful words that contribute to the overall meaning.\n",
        "\n",
        "<h4><font color='gold'><b>Removing Punctuations</b></font></h4>\n",
        "\n",
        "<b>What is it?</b>\n",
        "\n",
        "Removing punctuations involves getting rid of symbols like <font color='gren'><b>\".\"</b></font>, <font color='gren'><b>\",\"</b></font>, and <font color='gren'><b>\"!\"</b></font> from the text.\n",
        "\n",
        "\n",
        "```\n",
        "import re\n",
        "\n",
        "text=re.sub(r\"[^0-9a-zA-Z]\",\" \", text)\n",
        "```\n",
        "\n",
        "\n",
        "<b>Why do it?</b>\n",
        "\n",
        "Punctuations don't usually add much meaning in text analysis, so removing them makes the text cleaner and easier for the model to understand.\n",
        "<br><br>\n",
        "\n"
      ],
      "metadata": {
        "id": "rufmCSTm0-Tb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1T8WaJIy9IQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>Step 2: Feature Extraction</b></h3>\n",
        "\n",
        "Now after preparing our text, it is time to convert it into a numerical representation for the computer to undertand. This process is called <font color='gren'> <b>Word Embedding</b></font>\n",
        "<br><br>\n",
        "\n",
        "The word embedding could be implemented in 2 different ways.\n",
        "<br><br>\n",
        "\n",
        "<h4><b>Frequency Based Embedding</b>\n",
        "\n",
        "Frequency-Based Embedding involves representing words based on their frequency of occurrence in the text corpus. Words that occur more frequently are assigned higher weights.\n",
        "\n",
        "\n",
        "A <font color='gren'><b>text corpus</b></font> refers to a large and structured collection of texts in a particular language or domain. It serves as a representative sample of a language, providing a basis for linguistic analysis, natural language processing (NLP), and machine learning tasks.\n",
        "\n",
        "<br><br>\n",
        "<h4><b>Prediction Based Embedding</b>\n",
        "\n",
        "Bag of Words,\n",
        "TFIDF,\n",
        "N-Gram: Unigram, Bigram, ...\n",
        "Word Embedding, Word2Vec\n",
        "\n",
        "<br><br>\n",
        "<h3><b>Step 3: Classification </b></h3>\n",
        "\n",
        "RNN, GRU, LSTM\n",
        "Attention Models, Transformers,\n",
        "BERT"
      ],
      "metadata": {
        "id": "J4TCBEL_EYay"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bA3zcfN379cp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}